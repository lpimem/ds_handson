{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 2 Question 2 \n",
    "\n",
    "## 1. Question Analysis & Solution Designs \n",
    "\n",
    "### 1.1 Pre-process emails\n",
    "\n",
    "##### Parsing Raw Data\n",
    "\n",
    "All given email files are RFC 2822-based message documents. We can use a python built-in library `email` to parse the messages, and extract text contents. \n",
    "\n",
    "##### Removing HTML tags\n",
    "\n",
    "For some of the messages, the body of is in HTML format. We need to transform them into a equivalent structured plaintext. One way is use a regular expression to match each \"<>\" pair and remove them. But this way is not so accurate and may remove non-tag pairs or miss some html tags. Another way is to use a FSM to parse the document and transform accordingly. `html2text` is a 3-rd party library written by 'Aaron Swartz' which is doing the job well. And I'm using his work to extract texts from html documents.\n",
    "\n",
    "##### Implementation\n",
    "\n",
    "Please see file `email_processor.py` for detailed implementation.\n",
    "\n",
    "### 1.2 Build Data Set \n",
    "\n",
    "##### Feature Extraction\n",
    "\n",
    "First, we need to extract features from texts we just pre-processed. As requested in the question, we should use two methods respectively :\n",
    "\n",
    "- Word Count : use `CountVectorizer` \n",
    "- Tf-Idf : use `TfidfTransformer`\n",
    "\n",
    "##### Shuffle\n",
    "\n",
    "Second, to apply 5-fold cross validation effectively, we'd better shuffle the dataset first.\n",
    "\n",
    "### 1.3 K-fold cross validation \n",
    "\n",
    "`sklearn.cross_validation.KFold(n, n_fold)` method will return indexes to split the data set.\n",
    "\n",
    "### 1.4 Train models & score\n",
    "\n",
    "Use `<model>.fit(X_train, y_train)` to train each model. \n",
    "\n",
    "Use `<classifer>.predict(X_test)` to predict test data.\n",
    "\n",
    "Use `sklearn.metrics.<score_method>(y_test, y_predict)` to calculate score. \n",
    "\n",
    "## 2. Code Files & How To Run\n",
    "\n",
    "The code files is arranged in the following structure: \n",
    "\n",
    "```\n",
    "hw2\n",
    "  |-- hw2q2\n",
    "  |     |-- email_processor.py  (pre-process implementation)\n",
    "  |     |-- util.py             (detail function defs used by main) \n",
    "  |     |-- html2text.py        (3-rd party lib to process html)\n",
    "  |     |-- spam_filter.py      (main script)\n",
    "  |-- spamassasin               (data folder) \n",
    "```\n",
    "\n",
    "To run the code, first change directory to `hw2` folder, the execute: \n",
    "```Bash\n",
    "python3 hw2q2/spam_filter.py\n",
    "```\n",
    "\n",
    "## 3. Main Code (spam_filter.py)\n",
    "\n",
    "```Python\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer\n",
    "import logging\n",
    "import traceback\n",
    "from sklearn import cross_validation\n",
    "from sklearn.cross_validation import train_test_split as train_test_split\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import precision_score, f1_score, recall_score\n",
    "from sklearn.utils import shuffle\n",
    "from collections import OrderedDict\n",
    "\n",
    "\n",
    "from util import iter_files, pre_process_email, word_count, tfidf, train_model, load_features\n",
    "\n",
    "\n",
    "def experiment(counts, Y, isTfIdf=False):\n",
    "    '''\n",
    "        Conduct an experiment\n",
    "            @param counts: word counts\n",
    "            @param Y: lables \n",
    "            @param isTfIdf: use tf-idf or not.\n",
    "        \n",
    "        Each experiment will train 5 models as requested. \n",
    "        Then use 5-fold cross-validation method to split the data set.\n",
    "        For each splited data set, \n",
    "            1. train the model\n",
    "            2. collect scores\n",
    "        Then output the requested values. \n",
    "    '''\n",
    "    if isTfIdf:\n",
    "        counts = tfidf(counts)\n",
    "    models = {\n",
    "        \"1. Gaussian Naive Bayes\" : GaussianNB(),\n",
    "        \"2. Logistic Regression L2, C=1\": LogisticRegression(C=1.0, penalty='l2'),\n",
    "        \"3. Logistic Regression L2, C=0.5\": LogisticRegression(C=0.5, penalty='l2'),\n",
    "        \"4. Logistic Regression L1, C=1\": LogisticRegression(C=1, penalty='l1'),\n",
    "        \"5. Logistic Regression L1, C=0.5\": LogisticRegression(C=0.5, penalty='l1'),\n",
    "    }\n",
    "    score_methods = {\n",
    "        \"precision:\" : precision_score,\n",
    "        \"recall:\": recall_score,\n",
    "        \"f1_score:\": f1_score\n",
    "    }\n",
    "    orderedModels = OrderedDict(sorted(models.items(), key=lambda t: t[0]))\n",
    "    for config, model in orderedModels.items():\n",
    "        print(\"- \" * 10)\n",
    "        print(config)\n",
    "        kf_5 = cross_validation.KFold(len(Y), n_folds=5)\n",
    "        scores = {}\n",
    "        for train_idx, test_idx in kf_5:\n",
    "            X_train, X_test = counts[train_idx], counts[test_idx]\n",
    "            y_train, y_test = Y[train_idx], Y[test_idx]\n",
    "            clf = train_model(X_train.toarray(), y_train, model)\n",
    "            y_predict = clf.predict(X_test.toarray())\n",
    "            for item, method in score_methods.items():\n",
    "                score = method(y_test, y_predict)\n",
    "                if item not in scores:\n",
    "                    scores[item] = [score]\n",
    "                else:\n",
    "                    scores[item].append(score)\n",
    "        for item, score_list in scores.items():\n",
    "            print(\"    average\", item, np.mean(score_list))\n",
    "            print(\"    std\", item, np.std(score_list))\n",
    "\n",
    "\n",
    "def main(corpus_base_folder):\n",
    "    spam_folder = os.path.sep.join([corpus_base_folder, \"spam\"])\n",
    "    ham_folder = os.path.sep.join([corpus_base_folder, \"ham\"])\n",
    "    counts, Y  = load_features(\n",
    "        [spam_folder, ham_folder],\n",
    "        pre_process_email,\n",
    "        word_count,\n",
    "        [1, -1])\n",
    "    counts, Y = shuffle(counts, Y, random_state=40)\n",
    "    print(\"Using word count:\")\n",
    "    experiment(counts, Y, isTfIdf=False)\n",
    "    print()\n",
    "    print(\"= \" * 20)\n",
    "    print()\n",
    "    print(\"Using TF-IDF:\")\n",
    "    experiment(counts, Y, isTfIdf=True)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Result \n",
    "\n",
    "Execution result: \n",
    "```\n",
    "Using word count:\n",
    "- - - - - - - - - - \n",
    "1. Gaussian Naive Bayes\n",
    "    average recall: 0.778157466676\n",
    "    std recall: 0.0265749149059\n",
    "    average precision: 0.977554080464\n",
    "    std precision: 0.0230984826665\n",
    "    average f1_score: 0.865952756092\n",
    "    std f1_score: 0.01226531551\n",
    "- - - - - - - - - - \n",
    "2. Logistic Regression L2, C=1\n",
    "    average recall: 0.912288821645\n",
    "    std recall: 0.0242480881995\n",
    "    average precision: 0.989697641139\n",
    "    std precision: 0.00900620097033\n",
    "    average f1_score: 0.949188743673\n",
    "    std f1_score: 0.0124216314426\n",
    "- - - - - - - - - - \n",
    "3. Logistic Regression L2, C=0.5\n",
    "    average recall: 0.906832498886\n",
    "    std recall: 0.0248247346833\n",
    "    average precision: 0.989637145072\n",
    "    std precision: 0.00905349998163\n",
    "    average f1_score: 0.946186179968\n",
    "    std f1_score: 0.0129628858437\n",
    "- - - - - - - - - - \n",
    "4. Logistic Regression L1, C=1\n",
    "    average recall: 0.918858151305\n",
    "    std recall: 0.0295254914675\n",
    "    average precision: 0.970055398956\n",
    "    std precision: 0.013240941984\n",
    "    average f1_score: 0.943546074249\n",
    "    std f1_score: 0.0188891034469\n",
    "- - - - - - - - - - \n",
    "5. Logistic Regression L1, C=0.5\n",
    "    average recall: 0.90566025402\n",
    "    std recall: 0.0289049636861\n",
    "    average precision: 0.972262597742\n",
    "    std precision: 0.0112666810491\n",
    "    average f1_score: 0.93739278817\n",
    "    std f1_score: 0.0132572289671\n",
    "\n",
    "= = = = = = = = = = = = = = = = = = = = \n",
    "\n",
    "Using TF-IDF:\n",
    "- - - - - - - - - - \n",
    "1. Gaussian Naive Bayes\n",
    "    average recall: 0.785731506192\n",
    "    std recall: 0.0438602169706\n",
    "    average precision: 0.955281038565\n",
    "    std precision: 0.0339682312612\n",
    "    average f1_score: 0.861276667049\n",
    "    std f1_score: 0.0282112398114\n",
    "- - - - - - - - - - \n",
    "2. Logistic Regression L2, C=1\n",
    "    average recall: 0.907150571531\n",
    "    std recall: 0.0102048390634\n",
    "    average precision: 0.998230088496\n",
    "    std precision: 0.00353982300885\n",
    "    average f1_score: 0.950463535151\n",
    "    std f1_score: 0.00416039063932\n",
    "- - - - - - - - - - \n",
    "3. Logistic Regression L2, C=0.5\n",
    "    average recall: 0.907150571531\n",
    "    std recall: 0.0102048390634\n",
    "    average precision: 0.998230088496\n",
    "    std precision: 0.00353982300885\n",
    "    average f1_score: 0.950463535151\n",
    "    std f1_score: 0.00416039063932\n",
    "- - - - - - - - - - \n",
    "4. Logistic Regression L1, C=1\n",
    "    average recall: 0.919142638404\n",
    "    std recall: 0.0190066949001\n",
    "    average precision: 0.987421744922\n",
    "    std precision: 0.012747040162\n",
    "    average f1_score: 0.951931588752\n",
    "    std f1_score: 0.0122983819359\n",
    "- - - - - - - - - - \n",
    "5. Logistic Regression L1, C=0.5\n",
    "    average recall: 0.925007924271\n",
    "    std recall: 0.0143772245334\n",
    "    average precision: 0.987310345741\n",
    "    std precision: 0.00810302493776\n",
    "    average f1_score: 0.955046663372\n",
    "    std f1_score: 0.00705433463702\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [Root]",
   "language": "python",
   "name": "Python [Root]"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
